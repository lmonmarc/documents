%% -*- eval: (flyspell-mode 1); -*-

\chapter{Extraction et formalisation du parallélisme}

Le parallélisme dans un programme informatique est difficile à trouver automatiquement et la plupart du temps il est exprimé explicitement par le développeur. Il est alors nécessaire de lui offrir des outils permettant d'écrire le code parallèle simplement, en lui proposant notamment des fonctions et des mots-clés dans le langage choisi qui sont en accord à la fois avec les besoins matériels et à la fois avec les besoins algorithmiques. Ce chapitre dresse d'abord un état de l'art des principales solutions existantes, puis introduit les principaux objectifs du DSEL développé pendant le stage.

\section{Contexte}

Les applications parallèles sont utilisées depuis un certain nombres d'années afin d'obtenir des performances (en matière de rapidité, et en matière de taille du problème traité). Or il est difficile d'écrire des codes parallèles, ce qui a été évoqué au chapitre précédent. À ce titre divers outils pour faciliter la parallélisation sont apparus, tels que \textsf{ParaScope} dès $1989$ \cite{Art24} qui est éditeur de code interactif. Ces outils se décomposent en de nombreuses catégories à la fois par rapport aux utilisateurs qu'ils visent, et à la fois par rapport au parallélisme qu'ils permettent. Le cas d'application des stencils -- qui est le cas d'application du stage -- est alors explicité afin de voir comment interviennent les différents niveaux de parallélisme. 

\subsection{Expression du parallélisme}

Décrire les problèmes à résoudre et le parallélisme qu'ils peuvent utiliser peut se faire de différentes manières avec les moyens actuels. Notamment il est possible de regrouper quatre catégories qui sont les langages dédiés aux scientifiques (non spécialistes du HPC), les langages et compilateurs pour les développeurs de métier (mais non obligatoirement spécialistes du HPC), l'ensemble des bibliothèques et supports d'exécution spécialisés (destinés aux spécialistes du HPC), et en enfin les outils de formalisation des algorithmes employés (destinés aux spécialistes du HPC).

\paragraph{Langages dédiés aux scientifiques.}
Les langages dédiés aux scientifiques sont la plupart du temps des outils de simulation à destination d'experts dans ce domaine. Dans le cas des mathématiques par exemple, de nombreux logiciels définissant leur propre langage existent : \textsf{\href{http://www.wolfram.com/mathematica/}{Mathematica}}, \textsf{\href{http://fr.mathworks.com/}{MATLAB}} ou encore \textsf{\href{http://pari.math.u-bordeaux.fr/}{PARI/GP}} ; et une partie de leurs algorithmes sont parallélisés (au moins au niveau d'un processeur) pour des raisons de performances. Des initiatives plus poussées du côté du parallélisme sont également présentes en recherche comme \textsf{QIRAL} \cite{Art13,Art14} qui à partir d'algorithmes décrits en \LaTeX permet de générer un code parallèle optimisé pour les processeurs des ordinateurs courants -- mais pas pour les supercalculateurs --, il se base pour cela sur le système de réécriture \textsf{Maude} \cite{Art12}. La logique est alors la suivante : offrir à l'utilisateur les mêmes fonctions qui sont connues dans son domaine, en cachant l'implantation et la parallélisation de ces fonctions (telles qu'un calcul de facteurs premiers par exemple).

\paragraph{Langages dédiés au parallélisme.}
Quant il s'agit de développeurs souhaitant écrire du code parallèle sans forcément connaître les subtilités des machines d'exécutions, différents langages spécifiques ont été créés. De manière générale il s'agit en fait d'un langage déjà connu (\textsf{Java} ou \textsf{C/C++}) auquel sont ajoutés quelques mots-clés ou éléments de syntaxes (souvent pour les tableaux notamment) ; \textsf{\href{http://chapel.cray.com/}{Chapel}}, \textsf{\href{https://www.cilkplus.org/}{Cilk}}, \textsf{\href{http://upc.lbl.gov/}{UPC}}, \textsf{Lime} \cite{Art8}, \textsf{\href{http://x10-lang.org/}{X10}} et le langage proposé dans\cite{Art10} rentrent dans cette catégorie. Alors que les trois premiers cités sont très proches des langages d'origines, les trois derniers sont plus éloignés et proposent des paradigmes différents (comme les Map/Reduce dans \textsf{Lime} ou les horloges dans \textsf{X10}). Avec ces langages viennent souvent les compilateurs associés, toutefois parfois il s'agit plus simplement de réécriture automatique de code (vers un langage déjà existant) comme proposé par \textsf{Par4All} \cite{Ths2}. \textsf{Par4All} peut d'ailleurs être considéré comme un éditeur de code dédié au parallélisme, de même que le projet \textsf{Eclipse \href{http://www.eclipse.org/ptp/}{PTP}} (Parallel Tools Platform)ou les projets présentés dans les articles \cite{Art23,Art25}. Ces éditeurs rassemblent alors généralement plusieurs outils, et sont plus interactifs, mais leur parallélisation n'est pas toujours optimale.

\paragraph{Bibliothèques spécialisées.}
Pour atteindre un parallélisme optimal il est souvent nécessaire de descendre à un niveau plus proche du matériel. Plutôt que d'introduire quelques mots-clés supplémentaires, il s'agit alors de plusieurs dizaines de fonctions regroupées dans des bibliothèques. Il faut alors parfois utiliser différentes bibliothèques afin de gérer les différents niveaux de parallélisme (notamment interprocesseur et intraprocesseur). La bibliothèque utilisée dans le cadre du stage en fait partie : \textsf{\href{https://www.khronos.org/sycl}{SYCL}}. C'est celle qui est la plus haut niveau tout en offrant le plus de possibilités. La bibliothèque connue qui s'en rapproche le plus est \textsf{\href{https://www.khronos.org/opencl/}{OpenCL}} mais nécessite déjà plus d'efforts notamment pour gérer les communications entre les processeurs. En revanche \textsf{\href{http://openmp.org/wp/}{OpenMP}} (qui est en fait intégrée dans la plupart des compilateurs pour \textsf{Fortran}, \textsf{C/C++}) est beaucoup plus simple mais ne s'utilise que pour les processeurs génériques et non les processeurs graphiques. D'autres bibliothèques sont justement dédiés à la gestion de plusieurs types de processeurs en même temps, il s'agit des \emph{supports d'exécutions} tels que \textsf{\href{http://starpu.gforge.inria.fr/}{StarPU}} ou \textsf{\href{http://icl.utk.edu/parsec/}{PaRSEC}}. Comme la plupart des problèmes parallélisés sont liés à l'utilisation de grand tableaux, \textsf{Kokkos} \cite{Web5} et \textsf{\href{http://hpc.pnl.gov/globalarrays/}{Global Arrays}} permettent de simplifier leur utilisation et répartition sur les différents processeurs, mais ils ne gèrent pas le lancement des calculs contrairement aux supports d'exécutions. Plus spécifiquement encore \textsf{Blitz++} \cite{Art5} et dans la même idée l'article \cite{Art2} proposent des solutions simplifiant l'utilisation des tableaux, au sein d'un processeur. Enfin certaines rares bibliothèques se penchent plutôt sur les caractéristiques des algorithmes utilisés comme \textsf{SkePU} \cite{MstThs1}, qui s'apparente à un moteur d'exécution et utilise la formalisation de squelettes algorithmiques.


\paragraph{Formalisation des algorithmes.}
La formalisation des algorithmes parallèles se fait à travers différents outils comme la représentation polyédrique, utilisée lorsqu'il s'agit de parcours de tableaux au sein de boucles affines. Cette représentation permet d'ailleurs de mieux classifier les algorithmes, notamment en squelettes comme dans \textsf{SkePU} et \textsf{Bones} \cite{Art4,Art3,Art9}. Ces squelettes permettent de définir le motif d'accès aux données des tableaux impliqués dans le calcul de façon précise et ainsi de l'optimiser. Un tel exemple de motif -- plutôt général -- est le paradigme de \emph{Map/Reduce} qui est proposé par \textsf{SkePU} (ainsi que par le langage dédié \textsf{Lime} cité plus-haut). Cependant tous les algorithmes ne décrivent pas un calcul : certains sont au contraire destinés à ordonnancer les calculs, c'est-à-dire les répartir sur les différents processeurs disponibles. Encore plutôt à l'état de concept, c'est dans ce but que sont utilisés les \emph{composants} permettant les prédictions (et optimisations) du temps d'exécution tels que dans l'article \cite{Art7}, ainsi que les \emph{conteneurs intelligents} pour la gestion des communications avec la mémoire (et aussi les prédictions de temps) dans \textsf{SkePU} \cite[p.~78]{Ths1}.

\subsection{Cas d'application: les stencils}

Jacobi2D
Lattice QCD \cite{Art1}
3.5D blocking \cite{Art11}
Tiling stencil \cite{Art16}
Stencil pochoir \cite{Art18}
A lire ... \cite{Art19}

\section{Conception d'un DSEL pour les stencils}

A relire \cite{Art22}

\subsection{Objectifs sémantiques}

De quoi a-t-on besoin pour décrire un stencil

-> indices coefs

-> pattern du stencil

-> tableaux coefs

-> tableaux données

-> abstraire les structurations de données (copies tuiles, et data layout)

\subsection{Objectifs de performances}

-> tuiles/caches (data reuse)

-> calculs à la compilation

